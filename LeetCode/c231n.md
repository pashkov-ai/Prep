increase batch size by N -> scale starting LR by N
AdamW - is default, W (regularization, R)- is moved out of loss (L)
